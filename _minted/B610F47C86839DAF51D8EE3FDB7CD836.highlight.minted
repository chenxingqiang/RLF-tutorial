\begin{MintedVerbatim}[commandchars=\\\{\}]
\PYG{n}{training\PYGZus{}args} \PYG{o}{=} \PYG{n}{TrainingArguments}\PYG{p}{(}
    \PYG{n}{output\PYGZus{}dir} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{./results}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{num\PYGZus{}train\PYGZus{}epochs} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{,}
    \PYG{n}{per\PYGZus{}device\PYGZus{}train\PYGZus{}batch\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{4}\PYG{p}{,}
    \PYG{n}{gradient\PYGZus{}accumulation\PYGZus{}steps} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{,}
    \PYG{n}{learning\PYGZus{}rate} \PYG{o}{=} \PYG{l+m+mf}{2e\PYGZhy{}4}\PYG{p}{,}
    \PYG{n}{weight\PYGZus{}decay} \PYG{o}{=} \PYG{l+m+mf}{0.01}\PYG{p}{,}
    \PYG{n}{max\PYGZus{}grad\PYGZus{}norm} \PYG{o}{=} \PYG{l+m+mf}{0.3}\PYG{p}{,}
    \PYG{n}{logging\PYGZus{}steps} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
    \PYG{n}{save\PYGZus{}total\PYGZus{}limit} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{,}
\PYG{p}{)}
\PYG{o}{\PYGZca{}}\PYG{o}{\PYGZca{}}\PYG{n}{I}
\end{MintedVerbatim}
